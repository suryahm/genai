import matplotlib.pyplot as plt 
import tensorflow as tf 
from tensorflow.keras.layers import Dense 
 
class VAE(tf.keras.Model): 
    def __init__(self, d, z): 
        super().__init__() 
        self.enc = tf.keras.Sequential([Dense(256, 'relu'), Dense(z * 2)]) 
        self.dec = tf.keras.Sequential([Dense(256, 'relu'), Dense(d, 'sigmoid')]) 
     
    def call(self, x): 
        z_mean, z_log_var = tf.split(self.enc(x), 2, 1) 
        z = z_mean + tf.exp(0.5 * z_log_var) * tf.random.normal(tf.shape(z_mean)) 
        return self.dec(z), z_mean, z_log_var 
 
(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data() 
x_train, x_test = x_train.reshape(-1, 784) / 255, x_test.reshape(-1, 784) / 255 
 
vae, opt = VAE(784, 50), tf.optimizers.Adam(0.001) 
 
for _ in range(5): 
    for i in range(0, len(x_train), 100): 
        with tf.GradientTape() as tape: 
            recon, z_mean, z_log_var = vae(x_train[i:i+100]) 
            loss = tf.reduce_mean(tf.square(recon - x_train[i:i+100])) - 0.5 * tf.reduce_sum( 
                1 + z_log_var - z_mean**2 - tf.exp(z_log_var)) 
            opt.apply_gradients(zip(tape.gradient(loss, vae.trainable_variables), 
vae.trainable_variables)) 
        print(loss.numpy()) 
 
recon, _, _ = vae(x_test[:10]) 
plt.figure(figsize=(10, 5)) 
for i in range(10): 
    plt.subplot(2, 10, i + 1), plt.imshow(x_test[i].reshape(28, 28), cmap='gray'), plt.axis('off') 
    plt.subplot(2, 10, i + 11), plt.imshow(recon[i].numpy().reshape(28, 28), cmap='gray'), 
plt.axis('off') 
plt.show() 
