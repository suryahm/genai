import torch 
import torch.nn as nn 
import torch.optim as optim 
import torchvision 
import torchvision.transforms as transforms 
import matplotlib.pyplot as plt 
 
# Define the generator model 
class Generator(nn.Module): 
    def __init__(self, latent_dim): 
        super(Generator, self).__init__() 
        self.model = nn.Sequential( 
            nn.Linear(latent_dim, 128), 
            nn.ReLU(), 
            nn.Linear(128, 256), 
            nn.ReLU(), 
            nn.Linear(256, 512), 
            nn.ReLU(), 
            nn.Linear(512, 28 * 28),  # Output size for MNIST 
            nn.Tanh()  # Output activation function 
        ) 
 
    def forward(self, z): 
        return self.model(z).view(-1, 1, 28, 28)  # Reshape to image dimensions 
 
# Define the discriminator model 
class Discriminator(nn.Module): 
    def __init__(self): 
        super(Discriminator, self).__init__() 
        self.model = nn.Sequential( 
            nn.Flatten(), 
            nn.Linear(28 * 28, 512), 
            nn.LeakyReLU(0.2), 
            nn.Linear(512, 256), 
            nn.LeakyReLU(0.2), 
            nn.Linear(256, 1), 
            nn.Sigmoid()  # Output activation function 
        ) 
 
    def forward(self, img): 
        return self.model(img) 
 

 
latent_dim = 100 
generator = Generator(latent_dim) 
discriminator = Discriminator() 
 
# Define loss function and optimizers 
criterion = nn.BCELoss() 
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) 
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) 
 
# Load dataset (using MNIST for simplicity) 
transform = transforms.Compose([ 
    transforms.Resize(28), 
    transforms.ToTensor(), 
    transforms.Normalize([0.5], [0.5]) 
]) 
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, 
download=True) 
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, 
shuffle=True) 
 
# Training loop 
num_epochs = 10  # Reduced for faster execution 
for epoch in range(num_epochs): 
    for i, (imgs, _) in enumerate(train_loader): 
        # Create labels 
        real_labels = torch.ones(imgs.size(0), 1) 
        fake_labels = torch.zeros(imgs.size(0), 1) 
 
        # Train Discriminator 
        optimizer_D.zero_grad() 
        outputs = discriminator(imgs) 
        d_loss_real = criterion(outputs, real_labels) 
        d_loss_real.backward() 
 
        z = torch.randn(imgs.size(0), latent_dim) 
        fake_imgs = generator(z) 
        outputs = discriminator(fake_imgs.detach()) 
        d_loss_fake = criterion(outputs, fake_labels) 
        d_loss_fake.backward() 
 
        optimizer_D.step() 
 
        # Train Generator 
        optimizer_G.zero_grad()
            outputs = discriminator(fake_imgs) 
        g_loss = criterion(outputs, real_labels) 
        g_loss.backward() 
        optimizer_G.step() 
 
    # Print losses 
    if (epoch+1) % 1 == 0:  # Print every epoch 
        print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss_real.item() + 
d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}') 
 
# Generate and display images 
with torch.no_grad(): 
    z = torch.randn(16, latent_dim) 
    generated_imgs = generator(z) 
    generated_imgs = generated_imgs.view(-1, 1, 28, 28) 
 
# Plotting generated images 
grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=True) 
plt.imshow(grid.permute(1, 2, 0).cpu().numpy()) 
plt.axis('off') 
plt.show() 
