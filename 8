import os, torch, numpy as np 
import torch.nn as nn 
import matplotlib.pyplot as plt 
import torchvision.utils as vutils 
from torch.utils.data import DataLoader 
from torchvision import datasets, transforms 
from tqdm.auto import tqdm 
from IPython.display import HTML 
from matplotlib import animation 
 
device = "cuda" if torch.cuda.is_available() else "cpu" 
 
# Dataset and DataLoader 
train_dataset = datasets.FashionMNIST(root="datasets", train=True, download=True, 
transform=transforms.ToTensor()) 
dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True) 
real_data_batch = next(iter(dataloader)) 
 
# Displaying Images 
plt.figure(figsize=(10,10)); plt.axis('off'); plt.title("Training images") 
plt.imshow(np.transpose(vutils.make_grid(real_data_batch[0].to(device)[:64], padding=2, 
normalize=True).cpu(), (1, 2, 0))) 
plt.show() 
 
# Sample Image Display 
sample_data, sample_label = train_dataset[0] 
plt.imshow(sample_data.permute(1, 2, 0), cmap="gray"); plt.axis(False); 
plt.title(train_dataset.classes[sample_label]); plt.show() 
 
# Initializing Weights 
def weights_init(m): 
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d): 
nn.init.normal_(m.weight.data, mean=0.0, std=0.02) 
    if isinstance(m, nn.BatchNorm2d): nn.init.normal_(m.weight.data, mean=1.0, std=0.02); 
nn.init.constant_(m.bias.data, 0) 
 
# Generator Model 
class GeneratorModel(nn.Module): 
    def __init__(self, input_shape=100, output_channel=1): 
 
        super().__init__() 
        self.sequential_layer = nn.Sequential( 
            nn.Linear(input_shape, 7*7*256, bias=False), nn.BatchNorm1d(7*7*256), 
nn.LeakyReLU(), nn.Unflatten(1, (256, 7, 7)), 
            nn.ConvTranspose2d(256, 128, 5, 1, 2, bias=False), nn.BatchNorm2d(128), 
nn.LeakyReLU(), 
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False), nn.BatchNorm2d(64), 
nn.LeakyReLU(), 
            nn.ConvTranspose2d(64, output_channel, 4, 2, 1, bias=False), nn.Tanh() 
        ) 
    def forward(self, x): return self.sequential_layer(x) 
 
# Discriminator Model 
class DiscriminatorModel(nn.Module): 
    def __init__(self, input_features=1, hidden_features=10): 
        super().__init__() 
        self.sequential_gen = nn.Sequential( 
            nn.Conv2d(input_features, hidden_features, 3, 2, 1, bias=False), 
nn.BatchNorm2d(hidden_features), nn.LeakyReLU(), 
            nn.Conv2d(hidden_features, hidden_features, 3, 2, 1, bias=False), 
nn.BatchNorm2d(hidden_features), nn.LeakyReLU(), 
            nn.MaxPool2d(2, 2), nn.Conv2d(hidden_features, hidden_features, 3, 2, 1, 
bias=False), nn.BatchNorm2d(hidden_features), nn.LeakyReLU(), 
            nn.Conv2d(hidden_features, 1, 3, 2, 1, bias=False), nn.Sigmoid() 
        ) 
    def forward(self, x): return self.sequential_gen(x) 
 
# Instantiate models, apply weights, and setup optimizers 
generator, discriminator = GeneratorModel().to(device), DiscriminatorModel().to(device) 
generator.apply(weights_init); discriminator.apply(weights_init) 
loss_fn = nn.BCELoss() 
optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) 
optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) 
 
# Training Loop 
g_losses, d_losses, img_list, iters = [], [], [], 0 
real_label, fake_label = 1, 0 
print("[INFO] Starting the training Loop......") 
for epoch in tqdm(range(5)): 
    for i, data in tqdm(enumerate(dataloader, 0)): 
        # Update Discriminator 
        discriminator.zero_grad() 
        X_image_batch = data[0].to(device) 
        b_size = X_image_batch.size(0)
 label = torch.full((b_size,), real_label, dtype=torch.float, device=device) 
        output = discriminator(X_image_batch).view(-1) 
        real_error_d = loss_fn(output, label) 
        real_error_d.backward() 
        d_x = output.mean().item() 
 
        noise_data = torch.randn(b_size, 100, device=device) 
        fake_image = generator(noise_data) 
        label.fill_(fake_label) 
        output = discriminator(fake_image.detach()).view(-1) 
        fake_error_d = loss_fn(output, label) 
        fake_error_d.backward() 
        d_g_x = output.mean().item() 
 
        error_d = real_error_d + fake_error_d 
        optimizer_d.step() 
 
        # Update Generator 
        generator.zero_grad() 
        label.fill_(real_label) 
        output = discriminator(fake_image).view(-1) 
        error_g = loss_fn(output, label) 
        error_g.backward() 
        d_g_x2 = output.mean().item() 
        optimizer_g.step() 
 
        # Print and save losses 
        if i % 100 == 0: 
            print(f"[{epoch}/5] [{i}/{len(dataloader)}]\tLoss_D: {error_d.item():.3f}\tLoss_G: 
{error_g.item():.3f}") 
        g_losses.append(error_g.item()) 
        d_losses.append(error_d.item()) 
 
        # Check progress of generator 
        if i % 500 == 0: 
            with torch.no_grad(): 
                fake = generator(noise_data).detach().cpu() 
            img_list.append(vutils.make_grid(fake_image, padding=2, normalize=True)) 
 
        iters += 1 
 
# Save models 
torch.save(discriminator.state_dict(), "discriminator.pt") 
torch.save(generator.state_dict(), "generator.pt")
# Plot loss 
plt.figure(figsize=(10, 10)) 
plt.title("Loss Graph") 
plt.plot(g_losses, label="Generator Loss") 
plt.plot(d_losses, label="Discriminator") 
plt.ylabel("Loss") 
plt.xlabel("Iterators") 
plt.legend() 
plt.show() 
 
# Animation 
fig = plt.figure(figsize=(10, 10)) 
plt.axis(False) 
ims = [[plt.imshow(np.transpose(i.cpu(), (1, 2, 0)), animated=True)] for i in img_list] 
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True) 
HTML(ani.to_jshtml()) 
 
# Display real vs fake images 
real_batch = next(iter(dataloader)) 
plt.figure(figsize=(10, 10)) 
plt.subplot(1, 2, 1) 
plt.axis(False) 
plt.title("Real Images") 
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, 
normalize=True).cpu(), (1, 2, 0))) 
plt.subplot(1, 2, 2) 
plt.axis(False) 
plt.title("Fake Image") 
plt.imshow(np.transpose(img_list[-1].cpu(), (1, 2, 0))) 
plt.show() 
